**ğŸš– NYC Taxi Data Engineering**  

 **ğŸ› ï¸ End-to-End ETL + Warehouse + Analytics Pipeline**

Build a production-style data engineering workflow to ingest, clean, transform, warehouse, and analyze millions of NYC taxi trip records using Python, Pandas, Parquet, and DuckDB.

**â­ Project Summary**

This repository demonstrates a complete data engineering solution for the New York City taxi dataset â€” optimized for large-scale processing, data quality, and analytical insights.

## ğŸ“Œ Why This Project Matters

This pipeline showcases real data engineering skills including:

    âœ¨ Scalable batch ingestion  
    âœ¨ Schema drift handling  
    âœ¨ Analytics-ready data warehouse modeling  
    âœ¨ Clean ETL architecture  
    âœ¨ SQL-based KPI generation  
    âœ¨ Modular, resume-ready code structure

**ğŸ—ï¸ High-Level Architecture**

ğŸ“‚ Raw CSV Files (Millions of Rows)  
â†“  
ğŸ“¦ Chunked Ingestion (Pandas)  
â†“  
ğŸ“Œ Data Cleaning + Normalization  
â†“  
ğŸ—ƒï¸ Parquet Data Lake (Optimized Storage)  
â†“  
ğŸ§  DuckDB Warehouse (Fast SQL Analytics)
â†“  
ğŸ“ŠQueries  

**ğŸ§  Core Features**

âœ”ï¸ Chunked data ingestion (handles large files)  
âœ”ï¸ Data quality checks & cleaning  
âœ”ï¸ Parquet storage for efficient reloading  
âœ”ï¸ DuckDB analytic warehouse for SQL queries  
âœ”ï¸ Modular codebase with clear separation of concerns  
âœ”ï¸ Resilient to schema changes  
âœ”ï¸ Analytical KPI outputs and dashboards

**ğŸ“ Repository Structure**
```text
ğŸ“¦ nyc-taxi-data-engineering
â”£ ğŸ“‚ src/ # Modular ETL + analytics code
â”£ ğŸ“„ requirements.txt # Dependencies
â”£ ğŸ“„ README.md # Project overview
â”— ğŸ“„ sample_data/ # Sample taxi data for testing
